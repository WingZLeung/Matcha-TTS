[2025-01-22 15:34:40,431][matcha.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-01-22 15:34:40,439][matcha.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
CONFIG
├── data
│   └── _target_: matcha.data.text_mel_datamodule.TextMelDataModule             
│       name: SAP                                                               
│       train_filelist_path: /mnt/parscratch/users/acr22wl/SAP_challenge_output/
│       valid_filelist_path: /mnt/parscratch/users/acr22wl/SAP_challenge_output/
│       batch_size: 2                                                           
│       num_workers: 2                                                          
│       pin_memory: true                                                        
│       cleaners:                                                               
│       - english_cleaners3                                                     
│       add_blank: true                                                         
│       n_spks: 369                                                             
│       n_fft: 1024                                                             
│       n_feats: 80                                                             
│       sample_rate: 16000                                                      
│       hop_length: 160                                                         
│       win_length: 1024                                                        
│       f_min: 0                                                                
│       f_max: 8000                                                             
│       data_statistics:                                                        
│         mel_mean: -6.796193599700928                                          
│         mel_std: 2.4701178073883057                                           
│       seed: 1234                                                              
│       load_durations: false                                                   
│                                                                               
├── model
│   └── _target_: matcha.models.matcha_tts.MatchaTTS                            
│       n_vocab: 178                                                            
│       n_spks: 369                                                             
│       spk_emb_dim: 64                                                         
│       n_feats: 80                                                             
│       data_statistics:                                                        
│         mel_mean: -6.796193599700928                                          
│         mel_std: 2.4701178073883057                                           
│       out_size: null                                                          
│       prior_loss: true                                                        
│       use_precomputed_durations: false                                        
│       encoder:                                                                
│         encoder_type: RoPE Encoder                                            
│         encoder_params:                                                       
│           n_feats: 80                                                         
│           n_channels: 192                                                     
│           filter_channels: 768                                                
│           filter_channels_dp: 256                                             
│           n_heads: 2                                                          
│           n_layers: 6                                                         
│           kernel_size: 3                                                      
│           p_dropout: 0.1                                                      
│           spk_emb_dim: 64                                                     
│           n_spks: 1                                                           
│           prenet: true                                                        
│         duration_predictor_params:                                            
│           filter_channels_dp: 256                                             
│           kernel_size: 3                                                      
│           p_dropout: 0.1                                                      
│       decoder:                                                                
│         channels:                                                             
│         - 256                                                                 
│         - 256                                                                 
│         dropout: 0.05                                                         
│         attention_head_dim: 64                                                
│         n_blocks: 1                                                           
│         num_mid_blocks: 2                                                     
│         num_heads: 2                                                          
│         act_fn: snakebeta                                                     
│       cfm:                                                                    
│         name: CFM                                                             
│         solver: euler                                                         
│         sigma_min: 0.0001                                                     
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.0001                                                            
│         weight_decay: 0.0                                                     
│                                                                               
├── callbacks
│   └── model_checkpoint:                                                       
│         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
│         dirpath: /mnt/parscratch/users/acr22wl/Matcha-TTS/logs/train/ljspeech/
│         filename: checkpoint_{epoch:03d}                                      
│         monitor: epoch                                                        
│         verbose: false                                                        
│         save_last: true                                                       
│         save_top_k: 10                                                        
│         mode: max                                                             
│         auto_insert_metric_name: true                                         
│         save_weights_only: false                                              
│         every_n_train_steps: null                                             
│         train_time_interval: null                                             
│         every_n_epochs: 100                                                   
│         save_on_train_epoch_end: null                                         
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: 3                                                          
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│                                                                               
├── logger
│   └── wandb:                                                                  
│         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
│         save_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS/logs/train/ljspeech
│         offline: false                                                        
│         id: null                                                              
│         anonymous: null                                                       
│         project: lightning-hydra-template                                     
│         log_model: false                                                      
│         prefix: ''                                                            
│         group: ''                                                             
│         tags: []                                                              
│         job_type: ''                                                          
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS/logs/train/lj
│       max_epochs: 1000                                                        
│       accelerator: gpu                                                        
│       devices:                                                                
│       - 0                                                                     
│       precision: 16-mixed                                                     
│       check_val_every_n_epoch: 1                                              
│       deterministic: false                                                    
│       gradient_clip_val: 5.0                                                  
│                                                                               
├── paths
│   └── root_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS                      
│       data_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS/data/                
│       log_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS/logs/                 
│       output_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS/logs/train/ljspeech
│       work_dir: /mnt/parscratch/users/acr22wl/Matcha-TTS                      
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── run_name
│   └── ljspeech                                                                
├── tags
│   └── ['ljspeech']                                                            
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── ckpt_path
│   └── None                                                                    
└── seed
    └── 1234                                                                    
[rank: 0] Seed set to 1234
[2025-01-22 15:34:40,853][__main__][INFO] - Instantiating datamodule <matcha.data.text_mel_datamodule.TextMelDataModule>
[2025-01-22 15:34:43,395][__main__][INFO] - Instantiating model <matcha.models.matcha_tts.MatchaTTS>
[2025-01-22 15:34:43,405][matcha.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
AttributeError: module 'matcha.models' has no attribute 'matcha_tts'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/mnt/parscratch/users/acr22wl/Matcha-TTS/matcha/models/matcha_tts.py", line 9, in <module>
    from matcha.models.baselightningmodule import BaseLightningClass
  File "/mnt/parscratch/users/acr22wl/Matcha-TTS/matcha/models/baselightningmodule.py", line 87
    batch_size=batch_size
               
SyntaxError: invalid syntax. Perhaps you forgot a comma?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'matcha.models.matcha_tts.MatchaTTS':
SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('/mnt/parscratch/users/acr22wl/Matcha-TTS/matcha/models/baselightningmodule.py', 87, 24, '            batch_size=batch_size\n', 88, 20))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/parscratch/users/acr22wl/Matcha-TTS/matcha/utils/utils.py", line 77, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/mnt/parscratch/users/acr22wl/Matcha-TTS/matcha/train.py", line 58, in train
    model: LightningModule = hydra.utils.instantiate(cfg.model)
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
  File "/mnt/parscratch/users/acr22wl/.conda/envs/match/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'matcha.models.matcha_tts.MatchaTTS', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: model
[2025-01-22 15:34:43,437][matcha.utils.utils][INFO] - Output dir: /mnt/parscratch/users/acr22wl/Matcha-TTS/logs/train/ljspeech/runs/2025-01-22_15-34-40
Error executing job with overrides: ['experiment=ljspeech']
Error locating target 'matcha.models.matcha_tts.MatchaTTS', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: model

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
